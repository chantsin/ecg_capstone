{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13dc42e2",
   "metadata": {},
   "source": [
    "## ECG Classification Using Convolutional Neural Networks\n",
    "\n",
    "Author: Calvin Chan \n",
    "\n",
    "### Introduction\n",
    "In our last notebook, we will use the concept of convolution to model our ECG timeseries data. Traditionally, image analysis uses a 2D convolution to extract features from images, however since we are working with signals this would not work. Instead of 2D convolutions, we can convolve over our signals using a 1D framework. \n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "Here, we import all the necessary packages used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db2e2f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import load_functions as f\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_curve, roc_auc_score\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from Notebooks import ecg_cleaning as c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2385607",
   "metadata": {},
   "source": [
    "### Data Import\n",
    "\n",
    "Below we load our full data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e6ffd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Path\n",
    "path = '../data/physionet.org/files/ptb-xl/1.0.3/'\n",
    "metadata = pd.read_csv('../data/cleaned_metadata.csv')\n",
    "\n",
    "# Import data\n",
    "full_data = f.load_signal(path, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f77e9b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15677, 1000, 12), (15677,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at the data shape \n",
    "full_data[0].shape, full_data[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbb5e0b",
   "metadata": {},
   "source": [
    "We also want to look at Lead II only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34590d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15677, 1000), (15677,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slicing only for Lead II \n",
    "X = full_data[0][:,:,1]\n",
    "y = full_data[1]\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408f7b31",
   "metadata": {},
   "source": [
    "### Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a967adc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform target column into binary classes\n",
    "y = y.apply(lambda x: f.binary(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36b893bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnostic_superclass\n",
       "ABNO    8645\n",
       "NORM    7032\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7b53dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate LabelEncoder \n",
    "label = LabelEncoder()\n",
    "\n",
    "# Fit binary classes\n",
    "label.fit(y)\n",
    "\n",
    "# Transform classes\n",
    "y = label.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cb26b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking how our label is encoded\n",
    "label.transform(['ABNO', 'NORM'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ffe05f",
   "metadata": {},
   "source": [
    "As we can see, signals that are labeled `ABNO` are mapped to `0` and `NORM` are mapped `1`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29d05a1",
   "metadata": {},
   "source": [
    "#### Signal denoising using ecg_cleaning.py\n",
    "\n",
    "In this following section, we denoise our ECG signals using Fourier Tranforms. We have to specify the frequencies in which we want to take out for baseline wandering and powerline interference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3239935f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15677, 1000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20ee70d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low sampling frequency\n",
    "sig_len = 1000\n",
    "sampling_frequency = 100\n",
    "time = np.arange(0, sig_len) / sampling_frequency\n",
    "\n",
    "# Baseline and PLI removal\n",
    "signal_bl = np.apply_along_axis(c.baseline_removal, axis=1, arr=X, freq_start=0.1, freq_stop=1.5)\n",
    "signal_pli = np.apply_along_axis(c.high_freq_removal, axis=1, arr=signal_bl, freq_start=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9160008c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15677, 1000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_pli.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9149508",
   "metadata": {},
   "source": [
    "#### Train Test Split\n",
    "\n",
    "After preprocessing our signals, we can split our data set to training and testing. We will use `20%` of our data as testing and the rest as training. Since we have a data imbalance, we will include `stratify` as well.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d6ca143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12541, 1000), (3136, 1000), (12541,), (3136,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(signal_pli, y, test_size=0.2, stratify=y)\n",
    "\n",
    "# Checking the shape\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcb0132",
   "metadata": {},
   "source": [
    "#### Scaling \n",
    "\n",
    "Next, we want to scale our data. Since we are using using a neural network, as we calculate the gradient during backpropagation, distances can affect how well this is performed. We will use `StandardScaler` for our case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "877e1a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate standard scaler\n",
    "ss = StandardScaler()\n",
    "\n",
    "# Fit and transform training set\n",
    "X_train = ss.fit_transform(X_train)\n",
    "\n",
    "# Transform testing set\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea219c4",
   "metadata": {},
   "source": [
    "#### Transforming arrays into Torch Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce48c226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12541, 1000]) torch.Size([3136, 1000]) torch.Size([12541]) torch.Size([3136])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hw/t1cnzkgd34db0qbsch9qjy7c0000gn/T/ipykernel_52827/1608456114.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train, dtype=torch.float32)\n",
      "/var/folders/hw/t1cnzkgd34db0qbsch9qjy7c0000gn/T/ipykernel_52827/1608456114.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test = torch.tensor(X_test, dtype=torch.float32)\n",
      "/var/folders/hw/t1cnzkgd34db0qbsch9qjy7c0000gn/T/ipykernel_52827/1608456114.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train = torch.tensor(y_train, dtype=torch.float32)\n",
      "/var/folders/hw/t1cnzkgd34db0qbsch9qjy7c0000gn/T/ipykernel_52827/1608456114.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test = torch.tensor(y_test, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# Transforming independent variables\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "# Transforming dependent variables\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Sanity check\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7569a59",
   "metadata": {},
   "source": [
    "### Model Setup and Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "53f4cbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"Starting off with a simple cnn.\"\"\"\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        # Defining convolution layers\n",
    "        self.conv_layer = nn.Sequential(\n",
    "            \n",
    "            # Convolution block 1\n",
    "            nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=None),\n",
    "            \n",
    "            # Convolution block 2\n",
    "            nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=None),\n",
    "        )\n",
    "        \n",
    "        # Drop out layer \n",
    "        self.dropout = nn.Dropout1d(0.15)\n",
    "        \n",
    "        # Fully-connected layer\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(in_features=32*250, out_features=400),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=400, out_features=16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=16, out_features=1),\n",
    "        )\n",
    "        \n",
    "        # Output layer \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        # Loss function\n",
    "        self.binary_entropy_loss = nn.BCELoss()\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        \n",
    "    def forward(self, x): \n",
    "        \"\"\"Perform forward pass.\"\"\"\n",
    "\n",
    "        # Pass through convolution layers\n",
    "        x = self.conv_layer(x)\n",
    "        \n",
    "        # Flatten the output after convolution\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Apply drop out\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Pass through fully-connected layer\n",
    "        x = self.fc_layer(x)\n",
    "\n",
    "        # If training, repeat, else, compute output layer\n",
    "        if not self.training:\n",
    "            x = self.sigmoid(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"Make prediction.\"\"\"\n",
    "\n",
    "        predictions = self.forward(x)\n",
    "\n",
    "        # Hard class prediction: output from sigmoid with the higher percentage\n",
    "        hard_class_prediction = torch.argmax(predictions, dim=1)\n",
    "\n",
    "        return hard_class_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "73a26591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000]) torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "# Sample training \n",
    "\n",
    "sample = X_train[0]\n",
    "sample_label = y_train[0]\n",
    "\n",
    "print(sample.shape, sample_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c55d60ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1000])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.unsqueeze(0).unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ab929ebe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (conv_layer): Sequential(\n",
       "    (0): Conv1d(1, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (dropout): Dropout1d(p=0.15, inplace=False)\n",
       "  (fc_layer): Sequential(\n",
       "    (0): Linear(in_features=8000, out_features=400, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=400, out_features=16, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=16, out_features=1, bias=True)\n",
       "  )\n",
       "  (sigmoid): Sigmoid()\n",
       "  (binary_entropy_loss): BCELoss()\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing the model\n",
    "\n",
    "cnn_model = SimpleCNN()\n",
    "cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a57771",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_entropy_loss = nn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1b2740ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = cnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8ef01e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = cnn_model.binary_entropy_loss(outputs.sigmoid(), sample_label.unsqueeze(0).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5d828989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7903474569320679"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d3d6e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecgcap",
   "language": "python",
   "name": "ecgcap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
